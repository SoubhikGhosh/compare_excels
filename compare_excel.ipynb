{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "372dec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting fuzzywuzzy\n",
      "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: python-Levenshtein in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (0.27.1)\n",
      "Requirement already satisfied: Levenshtein==0.27.1 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from python-Levenshtein) (0.27.1)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.9.0 in /Users/soubhikghosh/Library/Python/3.9/lib/python/site-packages (from Levenshtein==0.27.1->python-Levenshtein) (3.12.2)\n",
      "Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
      "Installing collected packages: fuzzywuzzy\n",
      "Successfully installed fuzzywuzzy-0.18.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install fuzzywuzzy python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "438ab30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Any\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4eaa9920",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExcelFuzzyMapper:\n",
    "    def __init__(self, excel1_path: str, excel2_path: str, mapping_excel_path: str):\n",
    "        \"\"\"\n",
    "        Initialize the mapper with paths to three Excel files.\n",
    "        \n",
    "        Args:\n",
    "            excel1_path: Path to first Excel file (with a1, a2, a3... columns)\n",
    "            excel2_path: Path to second Excel file (with b1, b2, b3... columns)\n",
    "            mapping_excel_path: Path to mapping Excel file\n",
    "        \"\"\"\n",
    "        self.excel1_path = excel1_path\n",
    "        self.excel2_path = excel2_path\n",
    "        self.mapping_excel_path = mapping_excel_path\n",
    "        \n",
    "        # Load the Excel files\n",
    "        self.df1 = pd.read_excel(excel1_path)\n",
    "        self.df2 = pd.read_excel(excel2_path)\n",
    "        self.mapping_df = pd.read_excel(mapping_excel_path)\n",
    "        \n",
    "        # Ensure column names are strings\n",
    "        self.df1.columns = self.df1.columns.astype(str)\n",
    "        self.df2.columns = self.df2.columns.astype(str)\n",
    "        \n",
    "    def parse_mapping_expression(self, expr: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        Parse mapping expressions like 'a10+a12' into ['a10', 'a12']\n",
    "        \n",
    "        Args:\n",
    "            expr: Expression string (e.g., 'a10+a12' or 'a1')\n",
    "            \n",
    "        Returns:\n",
    "            List of column names\n",
    "        \"\"\"\n",
    "        # Remove spaces and split by '+'\n",
    "        expr = expr.strip().replace(' ', '')\n",
    "        columns = expr.split('+')\n",
    "        return columns\n",
    "    \n",
    "    def get_concatenated_value(self, df: pd.DataFrame, columns: List[str], row_idx: int) -> str:\n",
    "        \"\"\"\n",
    "        Get concatenated value from multiple columns for a specific row.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame to get values from\n",
    "            columns: List of column names\n",
    "            row_idx: Row index\n",
    "            \n",
    "        Returns:\n",
    "            Concatenated string value\n",
    "        \"\"\"\n",
    "        values = []\n",
    "        for col in columns:\n",
    "            if col in df.columns:\n",
    "                val = df.loc[row_idx, col]\n",
    "                if pd.notna(val):\n",
    "                    values.append(str(val))\n",
    "            else:\n",
    "                print(f\"Warning: Column '{col}' not found in DataFrame\")\n",
    "        \n",
    "        return ' '.join(values)\n",
    "    \n",
    "    def fuzzy_match_rows(self, str1: str, str2: str, threshold: int = 80) -> Tuple[bool, int]:\n",
    "        \"\"\"\n",
    "        Perform fuzzy matching between two strings.\n",
    "        \n",
    "        Args:\n",
    "            str1: First string\n",
    "            str2: Second string\n",
    "            threshold: Minimum similarity score (0-100)\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (is_match, similarity_score)\n",
    "        \"\"\"\n",
    "        # Convert to string and handle None values\n",
    "        str1 = str(str1) if pd.notna(str1) else ''\n",
    "        str2 = str(str2) if pd.notna(str2) else ''\n",
    "        \n",
    "        # Calculate similarity score\n",
    "        score = fuzz.ratio(str1, str2)\n",
    "        \n",
    "        return score >= threshold, score\n",
    "    \n",
    "    def process_mappings(self, threshold: int = 80) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Process all mappings and perform fuzzy matching.\n",
    "        \n",
    "        Args:\n",
    "            threshold: Minimum similarity score for matching (0-100)\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with fuzzy matching results\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        # Get primary key mapping (assuming first row contains primary key mapping)\n",
    "        if len(self.mapping_df) > 0:\n",
    "            primary_key_source = str(self.mapping_df.iloc[0]['source_column'])\n",
    "            primary_key_target = str(self.mapping_df.iloc[0]['target_column'])\n",
    "            \n",
    "            # Parse primary key columns\n",
    "            pk_source_cols = self.parse_mapping_expression(primary_key_source)\n",
    "            pk_target_cols = self.parse_mapping_expression(primary_key_target)\n",
    "            \n",
    "            print(f\"Primary key mapping: {primary_key_source} -> {primary_key_target}\")\n",
    "            \n",
    "            # Process each row in df1\n",
    "            for idx1, row1 in self.df1.iterrows():\n",
    "                # Get primary key value from df1\n",
    "                pk_value1 = self.get_concatenated_value(self.df1, pk_source_cols, idx1)\n",
    "                \n",
    "                # Find matching row in df2 based on primary key\n",
    "                best_match_idx = None\n",
    "                best_match_score = 0\n",
    "                \n",
    "                for idx2, row2 in self.df2.iterrows():\n",
    "                    pk_value2 = self.get_concatenated_value(self.df2, pk_target_cols, idx2)\n",
    "                    is_match, score = self.fuzzy_match_rows(pk_value1, pk_value2, threshold)\n",
    "                    \n",
    "                    if is_match and score > best_match_score:\n",
    "                        best_match_idx = idx2\n",
    "                        best_match_score = score\n",
    "                \n",
    "                if best_match_idx is not None:\n",
    "                    # Process all other column mappings for this row pair\n",
    "                    row_result = {\n",
    "                        'df1_row_index': idx1,\n",
    "                        'df2_row_index': best_match_idx,\n",
    "                        'primary_key_score': best_match_score,\n",
    "                        'primary_key_value': pk_value1\n",
    "                    }\n",
    "                    \n",
    "                    # Check all other mappings\n",
    "                    for mapping_idx, mapping_row in self.mapping_df.iterrows():\n",
    "                        if mapping_idx == 0:  # Skip primary key mapping\n",
    "                            continue\n",
    "                        \n",
    "                        source_expr = str(mapping_row['source_column'])\n",
    "                        target_expr = str(mapping_row['target_column'])\n",
    "                        \n",
    "                        source_cols = self.parse_mapping_expression(source_expr)\n",
    "                        target_cols = self.parse_mapping_expression(target_expr)\n",
    "                        \n",
    "                        value1 = self.get_concatenated_value(self.df1, source_cols, idx1)\n",
    "                        value2 = self.get_concatenated_value(self.df2, target_cols, best_match_idx)\n",
    "                        \n",
    "                        is_match, score = self.fuzzy_match_rows(value1, value2, threshold)\n",
    "                        \n",
    "                        row_result[f'mapping_{source_expr}_to_{target_expr}_score'] = score\n",
    "                        row_result[f'mapping_{source_expr}_to_{target_expr}_match'] = is_match\n",
    "                        row_result[f'value1_{source_expr}'] = value1\n",
    "                        row_result[f'value2_{target_expr}'] = value2\n",
    "                    \n",
    "                    results.append(row_result)\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def generate_match_report(self, results_df: pd.DataFrame, output_path: str = 'fuzzy_match_report.xlsx'):\n",
    "        \"\"\"\n",
    "        Generate a detailed match report in Excel format.\n",
    "        \n",
    "        Args:\n",
    "            results_df: DataFrame with matching results\n",
    "            output_path: Path to save the report\n",
    "        \"\"\"\n",
    "        with pd.ExcelWriter(output_path, engine='openpyxl') as writer:\n",
    "            # Write main results\n",
    "            results_df.to_excel(writer, sheet_name='Match Results', index=False)\n",
    "            \n",
    "            # Create summary sheet\n",
    "            summary_data = {\n",
    "                'Total Rows in Excel1': [len(self.df1)],\n",
    "                'Total Rows in Excel2': [len(self.df2)],\n",
    "                'Total Matched Rows': [len(results_df)],\n",
    "                'Match Rate': [f\"{len(results_df)/len(self.df1)*100:.2f}%\"]\n",
    "            }\n",
    "            summary_df = pd.DataFrame(summary_data)\n",
    "            summary_df.to_excel(writer, sheet_name='Summary', index=False)\n",
    "            \n",
    "            # Write mapping configuration\n",
    "            self.mapping_df.to_excel(writer, sheet_name='Mapping Configuration', index=False)\n",
    "        \n",
    "        print(f\"Match report saved to: {output_path}\")\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a12c541f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to run the fuzzy matching process.\n",
    "    \"\"\"\n",
    "    # Example usage\n",
    "    excel1_path = 'excel1_sample.xlsx'  # Replace with your actual file path\n",
    "    excel2_path = 'excel2_sample.xlsx'  # Replace with your actual file path\n",
    "    mapping_path = 'mapping_sample.xlsx'  # Replace with your actual file path\n",
    "    \n",
    "    # Create mapper instance\n",
    "    mapper = ExcelFuzzyMapper(excel1_path, excel2_path, mapping_path)\n",
    "    \n",
    "    # Process mappings with 80% similarity threshold\n",
    "    results = mapper.process_mappings(threshold=80)\n",
    "    \n",
    "    # Generate report\n",
    "    mapper.generate_match_report(results, 'fuzzy_match_results.xlsx')\n",
    "    \n",
    "    # Display sample results\n",
    "    print(\"\\nSample Results:\")\n",
    "    print(results.head())\n",
    "    \n",
    "    # Display match statistics\n",
    "    if len(results) > 0:\n",
    "        print(f\"\\nMatch Statistics:\")\n",
    "        print(f\"Total matched rows: {len(results)}\")\n",
    "        print(f\"Average primary key match score: {results['primary_key_score'].mean():.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c0dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_excels():\n",
    "    \n",
    "    # Create sample Excel 1\n",
    "    df1_sample = pd.DataFrame({\n",
    "        'a1': ['ID001', 'ID002', 'ID003', 'ID004'],\n",
    "        'a2': ['John Doe', 'Jane Smith', 'Bob Johnson', 'Alice Brown'],\n",
    "        'a3': ['New York', 'Los Angeles', 'Chicago', 'Houston'],\n",
    "        'a4': ['Engineer', 'Manager', 'Analyst', 'Developer'],\n",
    "        'a10': ['Dept', 'Dept', 'Dept', 'Dept'],\n",
    "        'a12': ['IT', 'HR', 'Finance', 'IT']\n",
    "    })\n",
    "    \n",
    "    # Create sample Excel 2\n",
    "    df2_sample = pd.DataFrame({\n",
    "        'b1': ['ID001', 'ID002', 'ID003', 'ID004'],\n",
    "        'b2': ['Software', 'Human', 'Financial', 'Software'],\n",
    "        'b5': ['John D.', 'Jane S.', 'Bob J.', 'Alice B.'],\n",
    "        'b6': ['Dept IT', 'Dept HR', 'Dept Finance', 'Dept IT'],\n",
    "        'b8': ['Engineer', 'Resources', 'Analyst', 'Developer'],\n",
    "        'b9': ['NY', 'LA', 'CHI', 'HOU']\n",
    "    })\n",
    "    \n",
    "    # Create sample mapping Excel\n",
    "    mapping_sample = pd.DataFrame({\n",
    "        'source_column': ['a1', 'a2', 'a3', 'a10+a12', 'a4'],\n",
    "        'target_column': ['b1', 'b5', 'b9', 'b6', 'b2+b8'],\n",
    "        'description': ['Primary Key', 'Name mapping', 'City mapping', 'Department concatenation', 'Role split mapping']\n",
    "    })\n",
    "    \n",
    "    # Save sample files (uncomment to create sample files)\n",
    "    df1_sample.to_excel('excel1_sample.xlsx', index=False)\n",
    "    df2_sample.to_excel('excel2_sample.xlsx', index=False)\n",
    "    mapping_sample.to_excel('mapping_sample.xlsx', index=False)\n",
    "    \n",
    "    print(\"Excel Fuzzy Mapper Script Ready!\")\n",
    "    print(\"\\nTo use this script:\")\n",
    "    print(\"1. Ensure you have the required packages installed:\")\n",
    "    print(\"   pip install pandas openpyxl fuzzywuzzy python-Levenshtein\")\n",
    "    print(\"\\n2. Prepare your mapping Excel file with columns:\")\n",
    "    print(\"   - 'source_column': Column(s) from Excel 1 (e.g., 'a1' or 'a10+a12')\")\n",
    "    print(\"   - 'target_column': Column(s) from Excel 2 (e.g., 'b1' or 'b2+b8')\")\n",
    "    print(\"   - 'description': Optional description of the mapping\")\n",
    "    print(\"\\n3. Update the file paths in the main() function\")\n",
    "    print(\"\\n4. Run the script!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0c2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #create_sample_excels()\n",
    "    main()\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
